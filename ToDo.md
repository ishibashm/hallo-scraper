# ハローワーク求人情報スクレイピング ToDoリスト (改訂版)

以下のタスクは、https://www.hellowork.mhlw.go.jp/kensaku/GECA110010.do から求人情報をスクレイピングするために必要な作業をフェーズごとに整理したものです。チェックボックスを使用して進捗を管理してください。

## フェーズ1: 調査・計画

- [ ] 1. 目的（抽出対象データ項目）を具体的にリストアップする。
- [ ] 2. `robots.txt` を確認し、アクセス許可/禁止パスを把握する。
- [ ] 3. 利用規約を確認し、スクレイピングに関する記述を把握する。
- [ ] 4. ブラウザ開発者ツールで以下の通信内容を正確に記録する。
  - [ ] 4.1. 最初の検索リスト表示時のPOSTリクエストURL、ヘッダー、**完全なペイロード**。
  - [ ] 4.2. ページネーション（「次へ」ボタンクリック時）のPOST/GETリクエストURL、ヘッダー、パラメータ/ペイロード。
  - [ ] 4.3. 求人詳細ページ表示時のGETリクエストURL、ヘッダー、クエリパラメータ。
- [ ] 5. 求人リストページから抽出が必要なキーパラメータ (`kJNo`, `jGSHNo`等) のCSSセレクタ/XPathを特定する。
- [ ] 6. 求人詳細ページから抽出が必要な全データ項目（HP, 電話番号等）のCSSセレクタ/XPathを特定する。
- [ ] 7. 技術選定を確定する（Python, Requests, Beautiful Soup 4, Pandas等を基本とする）。

## フェーズ2: 要件定義

- [ ] 1. 抽出する全データ項目の最終リストを定義する。
- [ ] 2. データ保存形式（CSV, Excel, DB等）とファイル命名規則を決定する。
- [ ] 3. エラーハンドリングの方針（リトライ回数、エラー時の処理）を決定する。
- [ ] 4. ログに出力する情報を定義する。
- [ ] 5. サーバー負荷対策（`sleep` 時間、並列処理の有無等）の方針を決定する。
- [ ] 6. User-Agent文字列を決定する。
- [ ] 7. プロジェクト全体の制約条件を再確認し、文書化する。

## フェーズ3: 設計・実装・テスト

- [ ] 1. プロジェクトフォルダ構成を決定する。
- [ ] 2. 開発環境を構築し、必要なライブラリをインストールする (`requirements.txt` 作成)。
- [ ] 3. 設定ファイル（URL, セレクタ等）を作成する。
- [ ] 4. セッション管理とPOSTリクエスト送信部分を実装・テストする。
- [ ] 5. リストページのパースとキーパラメータ抽出部分を実装・テストする。
- [ ] 6. 詳細ページURL組み立てとGETリクエスト送信部分を実装・テストする。
- [ ] 7. 詳細ページのパースとデータ抽出部分を実装・テストする。
- [ ] 8. ページネーション処理部分を実装・テストする。
- [ ] 9. データ加工・整形部分を実装・テストする。
- [ ] 10. データ保存部分を実装・テストする。
- [ ] 11. エラーハンドリングとログ出力部分を実装・テストする。
- [ ] 12. 全体を通した結合テストを実施する。
- [ ] 13. 出力されたデータを目視または別プログラムで検証する。

## フェーズ4: 運用・保守

- [ ] 1. 実行環境へのデプロイ（必要であれば）。
- [ ] 2. 定期実行を設定する（必要であれば）。
- [ ] 3. ログの監視方法を確立する。
- [ ] 4. サイト構造変更時の対応手順を定める。
- [ ] 5. 保守担当者と連絡方法を明確にする。

## 注意点

- **法的・倫理的責任:** スクレイピングは対象サイトの規約と法律を遵守し、サーバーに負荷をかけすぎないよう、常に倫理的に行ってください。
- **サイト変更:** ウェブサイトの構造は予告なく変更される可能性があります。スクリプトが動作しなくなった場合は、HTML構造や通信パラメータの変更を確認し、スクリプトを修正する必要があります。
- **情報公開範囲:** スクレイピングで取得できるのは、あくまでサイト上で公開されている情報のみです。電話番号やホームページが非公開の場合は取得できません。
